# 京东商品爬虫实现分布式,中间件(下载,代理)

[TOC]

## 实现分布式爬虫

* 步骤:
  1. 修改爬虫类
  2. 在settings文件中配置scrapy_redis
  3. 写一个程序用于把MongoDB中分类信息,放入到爬虫redis_key指定的列表中

1. 修改爬虫类
   + 步骤:
     	1. 修改继承关系:继承RedisSpider
      	2. 指定redis_key
      	3. 把重写start_requests改为make_request_from_data
    + 代码

```python
from scrapy_redis.spiders import RedisSpider
import pickle
#修改继承关系,继承RedisSpider
class JdProductSpider(RedisSpider):
    name = 'jd_product'
    allow_domains = ['jd.com','p.3.cn']
    #2. 指定redis_key
    redis_key = 'jd_product:category'

```



2. 修改`settings.py`

   1. ```css
      # redis数据连接
      REDIS_URL = 'redis://192.168.3.103:6379/0'
      # 去重容器类: 用于把已爬指纹存储到基于Redis的set集合中
      DUPEFILTER_CLASS = "scrapy_redis.dupefilter.RFPDuper"
      # 调度器:用于把待爬请求存储到基于Redis的队列
      SCHEDULER = "scrapy_redis.scheduler.Scheduler"
      
      # False,程序结束时候会清空Redis中已爬指纹和待爬请求
      # True,程序结束时会保留Redis中已爬指纹和待爬请求
      SCHEDULER_PERSIST = True #下次打开爬虫会继续接着上次记录开始爬
      
      ```

## 中间件

### 下载中间件

为了避免ip反爬,我们实现随机User-Agent和代理ip的中间件

* 步骤:
  1. 实现随机User-Agent的中间件
  2. 实现代理ip中间件
  3. 在settings.py文件开启,下载中间件

实现随机User-Agent的中间件

* 步骤: 
  * 准备User-Agent列表
  * 在middlewares.py中.实现RandomUserAgent类
  * 实现process_request方法
    * 如果请求是 https://cdnware.m.jd.com 设置一个iPhone的user-agent
    * 其它从User-Agent列表中随机选一个



### 代理ip中间件

* 在middlewares.py,中实现ProxyMiddleware类
* 实现process_request方法
  * 从代理池(付费代理ip接口中)获取一个代理ip,需指定代理IP的协议,和访问的域名
  * 设置给request.meta['proxy'] 传递
* 实现process_exception 方法
  * 当请求出现异常时候,代理池那些ip在本域名下是不可以用的.
* 